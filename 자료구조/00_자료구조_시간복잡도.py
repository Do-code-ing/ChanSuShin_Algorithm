"""
1. 알고리즘 (algorithm):
    알고리즘의 어원은 9세기 페르시아(이란-이라크) 수학자 Al-Khwarizmi의 라틴어 이름인
    algorismus와 수를 나타내는 그리스어 arithmos가 섞여 만들어졌다는게 정설이다.

    문제의 입력(input)을 수학적이고 논리적으로 정의된 연산과정을 거쳐
    원하는 출력(output)을 계산하는 절차이고,
    이 절차를 C나 Python과 같은 언어로 표현한 것이 프로그램(program) 또는 코드(code)가 된다.

    - 입력은 배열, 연결리스트, 트리, 해시테이블, 그래프와 같은 자료의 접근과 수정이 빠른 자료구조에 저장된다.
    - 자료구조에 저장된 입력 값을 기본적인 연산을 차례로 적용하여 원하는 출력을 계산한다.


2. 인류 최초의 알고리즘:
    그리스 수학자로 기하학의 아버지로 알려진 Euclid의 유명한 저서인
    "Elements"(BC.300)에 설명된 최대공약수(GCD)를 계산하는 알고리즘이 최초라고 알려져 있다.

    algorithm gcd(a, b)
        while a * b != 0 do
            if a > b
                a = a - b
            else
                b = b - a
        return a + b
    
    큰 수에서 작은 수를 빼는 과정을 큰 수가 작은 수보다 작아질 때까지 반복하고
    큰 수와 작은 수의 역할이 바뀌어 이 과정을 반복해서 작은 수가 0이 될 때까지 진행한다.
    이 과정은 결국에 큰수 % 작은수를 하면 된다는 것을 알 수 있다.

    algorithm gcd(a, b)
        while a * b != 0 do
            if a > b
                a = a % b
            else
                b = b % a
        return a + b
    
    위의 코드를 Python으로 변환해보자.
"""
def gcd(a, b):
    while a * b != 0:
        if a > b:
            a %= b
        else:
            b %= a
    return a + b
"""
    만약 a > b 라면, gcd(a, b)는 gcd(a-b, b)이고 동시에 gcd(b, a%b)가 된다.
    이 점을 이용하면 gcd 함수를 재귀함수로도 작성할 수 있다.
    예: gcd(16, 6) -> gcd(6, 4) -> gcd(4, 2) -> gcd(2, 0)

    직접 구현해보자.
"""
def gcd(a, b):
    # print(a, b)
    if a * b == 0:
        return a + b
    
    return gcd(b, a%b)
# print(gcd(16, 6))
"""
3. 가상컴퓨터, 가상언어, 가상코드 (Virtual Machine, Pseudo Language, Pseudo Code):
    자료구조와 알고리즘의 성능은 대부분 수행시간(시간복잡도)으로 정의되는 것이 일반적이다.
    이를 위해 실제 코드로 구현하여 실제 컴퓨터에서 실행한 후, 수행시간을 측정할 수도 있지만,
    HW/SW 환경을 한로 통일해야 하는 어려움이 있다.
    따라서, 가상언어로 작성된 가상코드를 가상컴퓨터에서 시뮬레이션하여 HW/SW에 독립적인 계산 환경에서 측정해야 한다.

    가상컴퓨터:
        현대 컴퓨터 구조는 Turing machine에 기초한 von Neumann 구조를 따른다.
        현재 가장 많이 사용하는 가상컴퓨터 모델은(real) RAM(Random Access Machine) 모델이다.
        RAM 모델은 CPU + memory + primitive operation으로 정의된다.
            - 연산을 수행하는 CPU
            - 임의의 크기의 실수도 저장할 수 있는 무한한 개수의 레지스터로 구성된 memory
            - 단위 시간에 수행할 수 있는 기본연산(primitive operation)의 집합
                - A = B (대입 또는 복사 연산)
                - 산술연산: +, -, *, / (나머지 % 연산은 허용 안되나, 본 강의에서는 포함한다.)
                - 비교연산: >, >=, <, <=, ==, !=
                - 논리연산: AND, OR, NOT
                - 비트연산: bit-AND, bit-OR, bit-NOT, bit-XOR, <<, >>
    
    가상언어:
        영어나 한국어와 같은 실제 언어보다 간단 명료하지만, C, Python 같은 프로그래밍 언어보다
        융통성이 있는 언어로, Python 유사하게 정의함.
        (수학적/논리적으로 모호함이 없이 명령어가 정의되기만 하면 됨)

        기본 명령어:
            - A = B (배정, 복사 연산)
            - 산술연산: +, -, *, /, %
            - 비교연산: >, >=, <, <=, ==, !=
            - 논리연산: AND, OR, NOT
            - 비트연산: bit-AND, bit-OR, bit-NOT, bit-XOR, <<, >>
            - 비교문: if, if else, if elseif ... else 문
            - 반복문: for 문, while 문
            - 함수정의, 함수호출
            - return 문
    
    가상코드:
        가상언어로 작성된 코드
        예: 배열 A의 n개의정수 중에서 최대값을 계산하는 가상코드
        (반드시 아래 형식을 따를 필요는 없음)

        algorithm arrayMax(A, n)
            input: n개의 정수를 저장한 배열 A
            output: A의 수 중에서 최대값
            currentMax = A[0]
            for i = 1 to n-1 do
                if currentMax < A[i]
                    currentMax = A[i]
            return currentMax
        
        위 코드에서 배정연산, 비교연산 등이 사용된다.


4. 알고리즘의 시간복잡도
    가상컴퓨터에서 가상언어로 작성된 가상코드를 실행(시뮬레이션)한다고 가정한다.
    특정 입력에 대해 수행되는 알고리즘의 기본연산의 횟수로 수행시간을 정의한다.
    문제는 입력의 종류가 무한하므로 모든 입력에 대해 수행시간을 측정하여 평균을 구하는 것은
    현실적으로 가능하지 않다는 점이다.
    따라서 최악의 경우의 입력(worst-case input)을 가정하여, 최악의 경우의 입력에 대한
    알고리즘의 수행시간을 측정한다.

    Checkpoint
    알고리즘의 수행시간 = 최악의 경우의 입력에 대한 기본연산의 수행 횟수

    최악의 경우의 수행시간은 입력 크기 n에 대한 함수 T(n)으로 표기 된다.
    T(n)의 수행시간을 갖는 알고리즘은 어떠한 입력에 대해서도 T(n) 시간 이내에 종료됨을 보장한다.
    실시간 제어가 필요하고 절대 안전이 요구되는 분야(항공, 교통, 위성, 원자로 제어 등)에선
    실제로 최악의 경우를 가정한 알고리즘 설계가 필요하기 때문에, 유효한 수행시간 측정방법이다.

    최악의 경우의 입력에 대해, 알고리즘의 기본연산(복사, 산술, 비교, 논리, 비트노리)의 횟수를 센다.
    예: n개의 정수중 최대 값을 찾는 알고리즘
        algorithm arrayMax(A, n)
            input: n개의 정수를 저장한 배열 A
            output: A의 수 중에서 최대값
            currentMax = A[0]
            for i = 1 to n-1 do
                if currentMax < A[i]
                    currentMax = A[i]
            return currentMax
        
        if 문의 결과에 따라 currentMax = A[i]가 실행되든지 아니든지 결정된다.
        최악의 경우의 입력은 무조건 currentMax = A[i]을 실행해야 하므로 if문을 계속 참(true)이 되도록 해야 한다.
        이 같은 입력은 A의 저장된 값이 오름차순으로 정렬된 경우이다.
        (즉, 오름차순으로 정렬된 n개의 값이 저장된 배열 A가 최악의 경우의 입력이라는 의미)
    
    최악의 입력에 대한 횟수 분석
        algorithm arrayMax(A, n)
            input: n개의 정수를 저장한 배열 A
            output: A의 수 중에서 최대값
            currentMax = A[0] (1번)
            for i = 1 to n-1 do
                if currentMax < A[i] (n-1번)
                    currentMax = A[i] (n-1번)
            return currentMax
        
        따라서 T(n) = 2n - 1이 된다.
        n = 10이면, T(10) = 19가 되어 19번 이내의 기본연산을 수행한다는 뜻이고,
        n = 200이면, T(200) = 399번의 기본연산을 수행한다는 의미이다.

    질문: 아래 알고리즘의 최악의 입력에 대해 수행하는 기본연산의 횟수는?
        algorithm arraySum(A, B, n)
            sum = 0 (1번)
            for i = 0 to n-1 do (n번)
                for j = i to n-1 do (logn번)
                    sum = sum + A[i]*B[j] (logn * 3번)
            return sum
        
        답: T(n) = 6nlogn + 1..?


5. Big-O 표기법
    최악의 입력에 대한 기본연산 횟수를 정확히 세는 건 일반적으로 귀찮고 까다롭다.
    정확한 횟수보다는 입력의 크기 n이 커질 때, 수행시간의 증가하는 정도가 훨씬 중요하다.
    수행시간 함수 T(n)이 n에 관한 여러 항의 합으로 표현된다면,
    함수 값의 증가율이 가장 큰 항 하나로 간략히 표기하는게 시간 분석을 간단하게 하는 데 큰 도움이 된다.
    예를 들어, T(n) = 2n + 5이면, 상수항보다는 n의 일차항이 T(n)의 값을 결정하게 되므로
    상수항을 생략해도 큰 문제가 없다.
    이렇게 최고차 항만을 남기고 나머지는 생략하는 식으로 수행시간을 간략히 표기하는 방법을
    근사적 표기법이라고 부르고, Big-O(대문자 O)를 이용하여 다음의 예처럼 표기한다.
        - T(n) = 2n + 5 -> T(n) = O(n)
        - T(n) = 3n^2 + 12n - 6 -> T(n) = O(n^2)
"""
# O(1) 시간 알고리즘:
def increment_one(a):
    return a + 1

# O(logn) 시간 알고리즘:
def number_of_bits(n):
    count = 0
    while n > 0:
        n = n // 2
        count += 1
    return count

# O(n) 시간 알고리즘:
def arrayMax(A, n):
    currentMax = A[0]
    for i in range(1, n):
        if currentMax < A[i]:
            currentMax = A[i]
    return currentMax

# O(n^2) 시간 알고리즘:
def array_sum(A, B, n):
    sum = 0
    for i in range(n):
        for j in range(n):
            sum += A[i] * B[j]
    return sum

# O(n^3) 시간 알고리즘:
def multi_matrices(A, B, n):
    # input: n * n 2d matrices A, B
    # output: C = A * B
    C = [[None] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            C[i][j] = 0
    for i in range(n):
        for j in range(n):
            for k in range(n):
                C[i][j] += A[i][k] * B[k][j]
    return C

# O(2^n) 이상의 시간이 필요한 알고리즘
def fibonacci(k):
    if k <= 1:
        return k
    return fibonacci(k-1) + fibonacci(k-2)

"""
[알고리즘 퍼즐 1] 독살의 음모를 밝혀라 !
    왕이 마실 와인 8병 중 하나에 강력한 독이 들어 있다. 한 방울만이라도
    치명적이다. 정상 와인을 아무리 섞어도 치명적이다. 다행히 검사장비를 구할
    수 있다. 단, 검사는 1시간이 필요하다. 왕은 무조건 1시간 후에 와인을
    마실테니 독이 든 병을 찾아내라는 명령을 내렸다. 이를 위해, 몇 대의 검사
    장비가 있으면 충분할까? (한 번 검사할 때에는 여러 병의 와인을 섞어 검사
    가능하다)

    8 -> 4, 4
    4 -> 2, 2
    2 -> 1, 1

    정답: 2대.. ?

[알고리즘 퍼즐 2] 25마리의 말 중에서 가장 빠른 세 마리를 선택하고 싶다.
    경기장엔 한 번에 다섯 마리 이하로 경주를 할 수 있고, 시계가 없어 기록을 잴 수 없고,
    대신 순위만 알 수 있다. 한 경주에서 같은 순위는 없다고 가정한다. 최소 몇 번의
    경주로 가장 빠른 세 마리를 알 수 있는가? (구글 인터뷰 질문)

    5마리씩 묶어서 5그룹을 만든 뒤 각 그룹별로 경주를 한 뒤 순위를 매긴다. (5번 경주)
    각 그룹의 1등끼리 경주한다. (6번 경주)
    각 그룹의 1등끼리 경주한 결과(이하 A)에서 1등 말을 뽑는다.
    A에서 4, 5등을 한 그룹은 제외한다.
    (남은 뽑아야할 말의 마리수는 2마리인데, 4등 그룹의 1등보다 이미 빠른 말이 2마리이기 때문이다.(2등, 3등))
    A = 1등그룹, 2등그룹, 3등그룹이 되는데,
    1등 그룹: (각 그룹의) 2등, 3등 
    2등 그룹: 1등, 2등
    3등 그룹: 1등
    이렇게 다섯마리를 뽑아 다시 경주를 하여 1등, 2등을 뽑는다. (7번 경주)
    1등 그룹에서 2등, 3등만 경주를 한 이유는, 다른 그룹의 1등들 보다 두 마리 모두 빠를 수 있기 때문이다.
    2등 그룹에서 1등, 2등만 경주를 한 이유는, 1등 그룹의 이유와 같다.
    3등 그룹에서 1등만 경주를 한 이유는, 3등 그룹의 1등이 뽑히게 되는 경우, 2등 그룹의 1등이 무조건 뽑혀야하기 때문이다.
    그러므로 3등 그룹의 2등은 절대로 뽑힐 수 없다.

    위 과정을 거쳐 최소 7번의 경주를 통해 가장 빠른 세 마리의 말을 선택할 수 있다.
"""